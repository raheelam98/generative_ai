{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raheelam98/generative_ai/blob/main/RAG/pinecone/pinecone_vector_db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Project : LangChain RAG with Google Gemini Flash and Pinecone**\n",
        "\n",
        "Creating a Retrieval-Augmented Generation (RAG) system using LangChain with Google Gemini Flash and Pinecone. This system will retrieve relevant context from a vector database and use that context to generate a more accurate and informed response from the Gemini model.\n",
        "\n"
      ],
      "metadata": {
        "id": "masu3dQcfeTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Implementation of RAG with Pinecone Vector DB**\n",
        "\n",
        "[Class-05: AI-201- Fundamentals of Agentic AI: Implementation of RAG with Pinecone Vector DB](https://www.youtube.com/watch?v=xQojOkqRbsU)\n",
        "\n",
        "Model : Google\n",
        "Vector DB : Pinecone\n",
        "\n",
        "#### **Tutorials**\n",
        "\n",
        "[LangChain Pinecone](https://python.langchain.com/docs/integrations/vectorstores/pinecone/)"
      ],
      "metadata": {
        "id": "PR5rqUXT8pN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i1SN2iGf7RDk"
      },
      "outputs": [],
      "source": [
        "# Install the required packages:\n",
        "%%capture --no-stderr\n",
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Credentials**"
      ],
      "metadata": {
        "id": "nXXkJQfshFVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# save key in varaiable\n",
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "# initialize pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n"
      ],
      "metadata": {
        "id": "wZOL6EphWdKI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zitvZtrAUGEI",
        "outputId": "1cc193a0-ccc2-48a7-fea9-fa37bac67a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pinecone.control.pinecone.Pinecone object at 0x7dfd3b719fd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Indexing**\n",
        "\n",
        "**Connect Vector Store to a Pinecone index**\n",
        "\n",
        "dimension is 768 becuse we are using google model\n",
        "\n",
        "Createing index through pinecone key"
      ],
      "metadata": {
        "id": "U0Ga0AMLhRnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Defining Index Name\n",
        "index_name=\"rag-pinecone-project-3\"\n",
        "\n",
        "# Creating a Pinecone Index\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "# Accessing the Index\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "V9UE8EsSUPcb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index)"
      ],
      "metadata": {
        "id": "p2374S7FOhuC",
        "outputId": "faea78e3-7499-4fbb-ca04-03be88064a97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pinecone.data.index.Index object at 0x7e64e56434d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Embedding**\n",
        "\n",
        "Use Google Gemini embeddings to vectorize documents.\n",
        "\n",
        "LangChain embeddings are vector representations of text used for semantic understanding and retrieval in AI workflows.\n",
        "\n",
        "Semantic refers to the meaning or interpretation of words, phrases, or symbols in a specific context.\n",
        "\n",
        "**Langchain Google Embeddings**\n",
        "\n",
        "[Google Generative AI Embeddings](https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/)"
      ],
      "metadata": {
        "id": "Hn85wZDKTcH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
      ],
      "metadata": {
        "id": "rnaLaXY4V2nD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"Pinecone Vector DB!\")\n",
        "vector[:5]  # print last 5"
      ],
      "metadata": {
        "id": "T391sUARXM9i",
        "outputId": "9c56bfc2-00da-485f-8ec6-ed67f317de23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012879692018032074,\n",
              " -0.06462990492582321,\n",
              " -0.05366327241063118,\n",
              " -0.021048594266176224,\n",
              " 0.035343751311302185]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "w0XBIQpopTKb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Manage vector store**\n",
        "\n",
        "**Add items to vector store**\n",
        "\n",
        "Add items to our vector store by using the **`add_documents`** function."
      ],
      "metadata": {
        "id": "fVbQQCbxY31f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")"
      ],
      "metadata": {
        "id": "5IGc-pSMuz4a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(document_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt-csKtbvaCe",
        "outputId": "fdadbecd-2a2a-4476-c5a4-783fd5c11507"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.' metadata={'source': 'tweet'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "# uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "# vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "id": "yZ3546qJu5-l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TMVvAkFwMNb",
        "outputId": "0d5dc768-f940-480d-d267-482ff692eba3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "uuid4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4PgJ_OdXAm7",
        "outputId": "58b47464-1816-40a6-d67c-bed4d2a178b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UUID('970194fa-684f-41a3-9a5e-e7b14504f2fa')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add data to the vector database using  **`add_documents()`**\n",
        "\n",
        "**`from langchain_pinecone import PineconeVectorStore`**\n",
        "\n",
        "**`vector_store = PineconeVectorStore(index=index, embedding=embeddings)`**\n",
        "\n",
        "**`vector_store.add_documents(documents=documents, ids=uuids)`**\n"
      ],
      "metadata": {
        "id": "85u2ZGWZYA1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uuids = [str(uuid4()) for _ in range(len(documents))]"
      ],
      "metadata": {
        "id": "96oMy5Nwv8oS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pprlwRo7Xdo1",
        "outputId": "b0aafc72-b36d-4bca-d3a1-7d716fb88f1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['b7cdd344-3fa3-47bb-9115-2ca0ad33f954',\n",
              " 'a9f87ae1-5d2b-4b51-a9f5-9b6795a2872a',\n",
              " '474f56e0-5995-484e-9eb4-9e5cbba7b576',\n",
              " 'ddbbfd63-95a1-4a76-a551-909df594f7e8',\n",
              " '754fc0ac-0d52-47e9-ab93-d9bb5a5bee83',\n",
              " 'd1ac6aa3-36b4-4324-832b-7a70455aa275',\n",
              " 'd0da7794-e907-4ef7-b9a1-c8173baead28',\n",
              " 'bc05d3f8-fb78-43b8-89c2-312ef42322b1',\n",
              " 'af122268-b546-4664-bbbb-c2472c53f839',\n",
              " '813fe0c6-afa9-4e11-9ea5-94d204d56c54']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Retrival\n",
        "\n",
        "**`similarity_search()`**"
      ],
      "metadata": {
        "id": "m87uzEY-adKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=3,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CudVH0Ola6hu",
        "outputId": "f8d8204b-7fd4-4dd4-deff-80d0dbf99dba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* I have a bad feeling I am going to get deleted :( [{'source': 'tweet'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`similarity_search_with_score()`**"
      ],
      "metadata": {
        "id": "mo7X-0SodiK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\"\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmfBWpyjdjuZ",
        "outputId": "92fd89db-ef5e-4eee-a2a4-b3fe876445ac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.667716] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n",
            "* [SIM=0.577374] I have a bad feeling I am going to get deleted :( [{'source': 'tweet'}]\n",
            "* [SIM=0.537337] I had chocalate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n",
            "* [SIM=0.533720] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=2, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OifPcNlPeJlZ",
        "outputId": "32bac67e-a176-4fbb-891f-fddb2cc794e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.667716] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n",
            "* [SIM=0.533720] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Keys\n",
        "# Get the GEMINI API key from user data\n",
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "CIzgS-I45Zw5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# Initialize the ChatGoogleGenerativeAI model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Specify the model\n",
        "    api_key=gemini_api_key,  # Pass the API key\n",
        "    )"
      ],
      "metadata": {
        "id": "3ZnfNand4SVm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\"k\": 1, \"score_threshold\": 0.5},\n",
        ")\n",
        "results = retriever.invoke(\"Stealing from the bank is a crime\")\n",
        "\n",
        "# print(results)\n",
        "for doc in results:\n",
        "    print(f\"{doc.metadata}: {doc.page_content}\")"
      ],
      "metadata": {
        "id": "WT7v7LHG-K-X",
        "outputId": "c0128775-39ef-4c5d-c72e-7d3fe4f0cba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': 'news'}: Robbers broke into the city bank and stole $1 million in cash.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "system_prompt = (\n",
        "    \"Use the given context to answer the question. \"\n",
        "    \"If you don't know the answer, say you don't know. \"\n",
        "    \"Use three sentence maximum and keep the answer concise. \"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ])\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "\n",
        "chain.invoke({\"input\": \"What is the down points in stock market\"})\n"
      ],
      "metadata": {
        "id": "1QLgAZ9b4C83",
        "outputId": "51e0c34c-755f-4188-91e5-ea816ba47a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the down points in stock market',\n",
              " 'context': [Document(id='af122268-b546-4664-bbbb-c2472c53f839', metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.')],\n",
              " 'answer': 'The stock market is down 500 points.  This is attributed to recession fears.'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}